---
title: Behavioural Projects Overview
subtitle: SWC/GCNU Neuroinformatics Unit
author: Niko Sirmpilatze, Sofia Mi√±ano, Chang Huan Lo
format:
  revealjs:
    footer: "Allen - IBL - NIU retreat | 2025-10-15"
---


## RSEs working on behaviour

[Neuroinformatics Unit (NIU)](https://neuroinformatics.dev/)

* Niko Sirmpilatze
* Chang Huan Lo
* Sofia Mi√±ano

# Behavioural experiments at SWC {background-color="#03A062"}

## Diversity of projects

- large collaborative projects  
  - Aeon
  - Crabs
  - Zoo
- lab-specific projects

## Aeon

:::: {.columns}

::: {.column width="40%"}

![](img/aeon-arena.jpg){height=500}
:::

::: {.column width="60%"}

- Mice foraging in a large arena
- 24-hour recordings
- Multiple cameras
- Multi-animal tracking (SLEAP)
- Plans to combine with Neuropixels
:::

::::

::: aside
*Image: Chang Huan Lo* | Multiple SWC labs, [NeuroGears](https://neurogears.org/), [DataJoint](https://datajoint.com/), et al.
:::

## Crabs

:::: {.columns}

::: {.column width="50%"}

![](img/crab-detection.jpg){}
:::

::: {.column width="50%"}
- Fiddler crabs
  - both in the wild
  - and in a *naturalistic* lab setting
- Detection and tracking with custom CNNs
:::

::::

::: aside
*Image: Sofia Mi√±ano* | 
[Branco Lab](https://www.sainsburywellcome.org/web/groups/branco-lab), 
[Margrie Lab](https://www.sainsburywellcome.org/web/groups/margrie-lab),
[UCL ARC](https://www.ucl.ac.uk/advanced-research-computing)
:::

## Zoo

:::: {.columns}

::: {.column width="50%"}

![](img/zoo-wasp.png){}
:::

::: {.column width="50%"}
- Videos acquired at the London Zoo
- Multiple species:
  - from üêù to üêò
- Diverse environments
- Pose estimation and tracking (DeepLabCut)
:::

::::

::: aside
*Image: Sanna Titus* |
[ZSL](https://www.zsl.org/),
[Branco Lab](https://www.sainsburywellcome.org/web/groups/branco-lab), 
[Margrie Lab](https://www.sainsburywellcome.org/web/groups/margrie-lab),
[UCL ARC](https://www.ucl.ac.uk/advanced-research-computing)
:::

## Lab-specific projects

:::: {.columns}

::: {.column width="50%"}

![](img/EPM-mouse.png){}

:::

::: {.column width="50%"}

![](img/open-field-mouse.png){}

:::

::::

::: aside
*Images: Loukia Katsouri* |
[O'Keefe Lab](https://www.sainsburywellcome.org/web/groups/okeefe-lab)
:::

## Diversity of needs

- species
- environments
- number of animals
- pose estimation and tracking tools
- performance

## Our priority

:::: {.columns}

::: {.column width="50%"}
Standardised video analysis pipeline, **but**:

- Flexible
- Modular
- Extensible
:::

::: {.column width="50%"}
```{mermaid}
%%| file: diagrams/video-pipeline.mmd
%%| fig-height: 500px
``` 
:::

::::

## How to achieve this? {.smaller}

::: {.fragment}
* Make existing tools easier to use for researchers
  * documentation and teaching
  * build easy-to-use interfaces/wrappers
:::

::: {.fragment}
* Develop new tools to fill gaps in the ecosystem
  * `movement` Python package
:::

::: {.fragment}
* Make existing and new tools interoperable
  * The *PoseInterface* project?
:::

# Working with existing tools {background-color="#03A062"}

## Pose estimation libraries {.smaller}

:::: {.columns}

::: {.column width="40%"}

Pose estimation libraries:

- [DeepLabCut](http://www.mackenziemathislab.org/deeplabcut)
- [SLEAP](https://sleap.ai/)
- Many others...

**But**:

- Know-how required
- GPU-intensive
:::

::: {.column width="60%"}
```{mermaid}
%%| file: diagrams/video-pipeline_emph-pose.mmd
%%| fig-height: 500px
``` 
:::

::::

## Pose estimation libraries

- Centrally installed modules on HPC cluster

```{.bash}
module load deeplabcut
module load SLEAP
```

::: {.fragment}
- Curate [detailed how-to guides](https://howto.neuroinformatics.dev/data_analysis/HPC-module-SLEAP.html){preview-link="true" style="text-align: center"}
:::

::: {.fragment}
- Deliver [courses and workshops](https://software-skills.neuroinformatics.dev/){preview-link="true" style="text-align: center"} on:
  - Pose estimation
  - Linux and HPC
:::


## Accessible interfaces

[WAZP web app](https://sainsburywellcomecentre.github.io/WAZP/)

![](img/WAZP-roi-drawing.png){height=450}

::: aside
With Sofia Mi√±ano & Sam Cunliffe of [UCL ARC](https://www.ucl.ac.uk/advanced-research-computing)
:::


# Developing new tools {background-color="#03A062"}

## What happens after pose estimation and tracking?

```{mermaid}
%%| file: diagrams/video-pipeline_emph-kino.mmd
%%| fig-height: 500px
``` 

## Some common metrics {auto-animate=true auto-animate-id="kino-graph"}
```{mermaid}
%%| file: diagrams/kinematics.mmd
%%| fig-height: 500px
```

## Some common metrics {auto-animate=true auto-animate-id="kino-graph"}

```{mermaid}
%%| file: diagrams/kinematics_wROI.mmd
%%| fig-height: 500px
```

## Existing tools

| Tool | Stars | Last Commit |
| ---- | ---- | ---- |
| [movingpandas](https://github.com/movingpandas/movingpandas) | ~1k | Aug 2023 |
| [AmadeusGPT](https://amadeusgpt.kinematik.ai/app/) | 117 | Sep 2023 |
| [DLC2Kinematics](https://github.com/AdaptiveMotorControlLab/DLC2Kinematics) | 109 | Jun 2023 |
| [traja](https://github.com/traja-team/traja) | 79 | Oct 2022 |
| [PyRat](https://github.com/pyratlib/pyrat) | 30 | Feb 2023 |


## Enter `movement`

:::: {.columns}

::: {.column width="55%"}
![](img/movement-repo-screenshot.png)
:::

::: {.column width="45%"}
Kinematic analysis of animal movements for neuroscience and ethology research.

- [GitHub repository](https://github.com/neuroinformatics-unit/movement)
- [Documentation](https://neuroinformatics-unit.github.io/movement/){preview-link="true" style="text-align: center"}
- [PyPI package](https://pypi.org/project/movement/)
:::

::::


## `movement` features {.smaller}

::: {.fragment}
* __I/O:__ (see [example](https://neuroinformatics-unit.github.io/movement/auto_examples/load_and_explore_poses.html#sphx-glr-auto-examples-load-and-explore-poses-py){preview-link="true" style="text-align: center"})
  * ‚úÖ import pose tracks from `DeepLabCut` and `SLEAP` 
  * ‚úÖ represent pose tracks in common data structure
  * ü§î export data for downstream analysis (e.g. for classifiers)
:::

::: {.fragment}
* __Plotting:__ üèóÔ∏è plot pose tracks, ROIs, etc.
:::

::: {.fragment}
* __Preproc:__ ü§î pose track interpolation, smoothing, resampling, etc.
:::

::: {.fragment}
* __Kinematics:__ ü§î velocity, acceleration, orientation, etc.
:::

::: {.fragment}
* __Arena:__ ü§î ROI support and coordinate transformations
:::

## `movement` GUI

![](img/output.gif){height=500}

::: aside
Explore the multidimensional image viewer [napari](https://napari.org/stable/)
:::

## Why napari?

It already comes with built-in [layers](https://napari.org/stable/api/napari.layers.html){preview-link="true" style="text-align: center"} for:

- `Image`: video frames?
- `Points`: keypoints?
- `Shapes`: ROIs?
- `Tracks`: pose tracks?
- `Vectors`: velocity, acceleration, etc.?

# Interoperability {background-color="#03A062"}

## Video compression {.smaller}

:::: {.columns}

::: {.column width="50%"}
```{mermaid}
%%| file: diagrams/video-pipeline_emph-compr.mmd
%%| fig-height: 500px
``` 
:::

::: {.column width="50%"}
* What's the best format/codec for saving videos?
* Trade-off between file size and quality
* Compressed videos must be readable by all major pose estimation libraries
* Ideally videos are compressed during (or directly after) acqusition
:::

::::

::: aside
Could be addressed by a larger collaboration
:::

## Pose Interface? {.smaller}

:::: {.columns}

::: {.column width="50%"}
```{mermaid}
%%| file: diagrams/video-pipeline_emph-pose.mmd
%%| fig-height: 500px
``` 
:::

::: {.column width="50%"}
Similar to [SpikeInterface](https://spikeinterface.readthedocs.io/en/latest/)

  * Common input format (label data once)
  * Choose a number of pose estimation libraries
  * Common output format
:::

::::

::: aside
Would allow for flexibility and facilitate systematic comparisons
:::

## From behaviour to actions {.smaller}

:::: {.columns}

::: {.column width="50%"}
```{mermaid}
%%| file: diagrams/video-pipeline_emph-classifiers.mmd
%%| fig-height: 500px
``` 
:::

::: {.column width="50%"}
Several tools:

- [SimBA](https://github.com/sgoldenlab/simba)
- [MoSeq](https://dattalab.github.io/moseq2-website/index.html)
- [VAME](https://edspace.american.edu/openbehavior/project/vame/)
- [B-SOID](https://github.com/YttriLab/B-SOID)
- [DLC2action](https://github.com/amathislab/DLC2action)
:::

::::

::: aside
We need a standard way of passing data to these tools.
:::


# Appendix {background-color="#03A062"}

## `xarray` data structures {.smaller visibilty="uncounted"}

`DataArray` is an N-dimensional generalisation of pandas `Series`.

- `values`: a numpy.ndarray holding the array's values
- `dims`: names for each axis (e.g., ['time', 'individuals', 'keypoints'])
- `coords`: e.g., list of animal names, bodypart names
- `attrs`: an `OrderedDict` to hold arbitrary metadata (attributes).

::: {.fragment}
`Dataset` is a collection of aligned `DataArray` objects.
![](img/xarray-logo.webp){height=200}
:::

## `xarray` pros and cons {.smaller visibilty="uncounted"}

:::: {.columns}

::: {.column width="50%"}
__Pros:__

- label-based indexing
- `numpy`-like vectorisation and broadcasting
- `pandas`-like aggregation + groupby
- `dask` + `zarr` integration for parallel computing
:::

::: {.column width="50%"}
__Cons:__

- not as widely known as `numpy`/`pandas`
- learning curve
:::

::::

## `movement` design aspirations {visibilty="uncounted"}

* __Modularity:__ small, reusable, composable functions
* __Flexibility:__ future-proof, extensible, configurable
* __Accessibility:__ API + GUI, muli-platform, docs, tutorials
* __Maintainability:__ Tests, CI/CD
* __Performance:__ parallelization
