---
title: Behavioural Projects Overview
subtitle: SWC/GCNU Neuroinformatics Unit
author: Niko Sirmpilatze, Sofía Miñano, Chang Huan Lo
format:
  revealjs:
    footer: "IBL-AIND-NIU retreat | 2025-10-15"
---


## RSEs working on behaviour

::: {layout-nrow=1}

![Niko Sirmpilatze](img/niko_sirmpilatze.png)

![Sofía Miñano](img/sofia_minano.png)

![Chang Huan Lo](img/chang_huan_lo.png)

:::

## Behavioural experiments at SWC

```{python}
#| code-fold: true

from matplotlib import pyplot as plt
from movement import sample_data


fname_dict = {
  "Pupil tracking (Margrie Lab)": "DLC_rotating-mouse_eye-tracking_stim-black.predictions.h5",
  "EPM (O'Keefe Lab)": "DLC_single-mouse_EPM.predictions.h5",
  "Home-cage monitoring (O'Keefe Lab)": "DLC_smart-kage3_datetime-20240417T090006.predictions.h5",
  "Foraging mice (aeon.swc.ucl.ac.uk)": "SLEAP_three-mice_Aeon_proofread.analysis.h5",
  "Social decision-making (Duan Lab)": "SLEAP_two-mice_octagon.analysis.h5",
  "Foraging wasp (Margrie & Branco Labs)": "DLC_single-wasp.predictions.h5",
}

ds_dict = {
  lab: sample_data.fetch_dataset(fname, with_video=False)
  for lab, fname in fname_dict.items()
}

frame_dict = {
  lab: plt.imread(ds.frame_path) for lab, ds in ds_dict.items()
}
```

```{python}
# | code-fold: true

# Make a figure with 2 rows and 3 columns
fig, ax = plt.subplots(2, 3, figsize=(12, 7))

for i, (lab, frame) in enumerate(frame_dict.items()):
    r = i // 3
    c = i % 3
    ax[r, c].imshow(frame)
    ax[r, c].set_title(lab)
    ax[r, c].axis("off")

fig.tight_layout()
plt.show()
```

## Tracking fiddler crabs in the field

![](img/crabs_beach.png){height=550}

::: footer
*Sofía Miñano*, working with the Margrie & Branco labs.
:::

## Our approach

::: {.callout-note}
## A single standardised workflow won't do

We need general-purpose, versatile, interoperable tools that can be
reliably mixed and matched to different needs.
:::

::: {.fragment}
- What are common workflows and tasks?
- Which needs are well-served?
  - **Support and teach existing tools.**
- Which needs are not covered?
  - **Develop new tools.**
:::

## Common workflows

![](img/neuroethology_workflow.png){height=500}

::: footer
Modern computational neuroethology workflow
:::


## Markerless pose estimation


:::: {.columns}

::: {.column width="60%"}
![](img/pose_tracking.png)
:::

::: {.column width="40%"}
![deeplabcut.org](img/MousereachGIF.gif)
:::

::::

:::: {.fragment}

::: {.callout-note}
## Supporting & teaching pose estimation tools at SWC

- We have deployed [DeepLabCut](https://www.mackenziemathislab.org/deeplabcut) & [SLEAP](https://sleap.ai/) as [HPC modules](https://howto.neuroinformatics.dev/data_analysis/HPC-module-SLEAP.html).
- We provide regular [hands-on training on using SLEAP](https://animals-in-motion.neuroinformatics.dev/latest/03-sleap-tutorial.html).
:::

::::

## What about other CV tasks? {.smaller}

Computer vision (CV) tasks other than pose estimation are less accessible.

![](img/ethology_overview.png)

- Mix-and-match computer vision tools for animal behaviour analysis.
- Still under early development (talk to *Sofía*!)

::: footer
[ethology.neuroinformatics.dev](https://ethology.neuroinformatics.dev/)
:::


## What happens after tracking?


![](img/gap_after_tracking.png)


## `movement` overview {.smaller}

![](img/movement_overview.png){height=450}


::: aside
{{< fa download >}} ~60k downloads (PyPI + conda-forge)

{{< fa brands github >}} 26 code contributors, 50% from outside UCL

{{< fa message >}} Public forum hosts 82 members across 53 threads
:::

::: footer
[movement.neuroinformatics.dev](https://movement.neuroinformatics.dev/)
:::


## `movement` example applications {.smaller}

::: {layout="[[25, 25, 20, 20], [40, 20, 40]]"}

::: {.fragment fragment-index=2}
![](img/centroid_trajectory.png)
:::

::: {.fragment fragment-index=2}
![](img/occupancy_heatmap.png)
:::

::: {.fragment fragment-index=3}
![](img/rois.png)
:::

::: {.fragment fragment-index=3}
![](img/head_direction_angle.png)
:::

::: {.fragment fragment-index=1}
![](img/raw_vs_clean.png)
:::

::: {.fragment fragment-index=4}
![](img/pupil_keypoints.png)
:::

::: {.fragment fragment-index=4}
![](img/pupil_velocity_black.png)
:::

:::

::: aside
See also [movement.neuroinformatics.dev](https://movement.neuroinformatics.dev/) > Examples
:::


::: footer
[Sample data](https://movement.neuroinformatics.dev/user_guide/input_output.html#sample-data): __Elevated Plus Maze__ from *Loukia Katsouri* | __Pupil Tracking__ from *Sepi Keshavarzi*.
:::

## `movement` GUI

{{< video "img/gui_tracks_demo.mp4" aspect-ratio="16x9" >}}

::: footer
[Sample data](https://movement.neuroinformatics.dev/user_guide/input_output.html#sample-data) from *Ann Duan's Lab*.
:::

## `movement` outlook {.smaller}

:::: {columns}

::: {.column width="70%"}

::: {.fragment fragment-index=1}
More advanced methods for outlier detection & smoothing

- :hourglass_flowing_sand: [EKS](https://github.com/paninski-lab/eks) > `movement` data loader (in progress, [PR #670](https://github.com/neuroinformatics-unit/movement/pull/670))
- :thinking: Incorporate approaches from [LightningPose](https://lightning-pose.readthedocs.io/en/latest/) & [EKS](https://github.com/paninski-lab/eks)
:::

::: {.fragment fragment-index=2}
Modules for specialised applications

- :thinking: gait analysis, pupillometry, collective behaviour
:::

::: {.fragment fragment-index=3}
Integration with tools for neurophysiological data analysis

- :thinking: Leverage [NWB](https://nwb.org/) + [pynapple](https://pynapple.org/)
:::

:::

::: {.column width="30%" .fragment fragment-index=3}

![](img/neural_behaviour_correlation.png)

:::

::::

## What about behaviour segmentation? {.smaller}

:::: {columns}

::: {.column width="50%"}
![](img/behaviour_segmentation.png)
:::

::: {.column width="50%"}
We have explored some existing tools:

- [keypoint-moseq](https://keypoint-moseq.readthedocs.io/en/latest/) (unsupervised)
- [JABS-behavior-classifier](https://github.com/KumarLabJax/JABS-behavior-classifier) (supervised)

Would love to hear your experiences with others!
:::

::::

::: {.callout-note}
## No single go-to solution yet

:thinking: Is there scope for collaborating on improving existing tools or
developing a new robust, easy-to-use interface for behaviour segmentation?
:::

## Some remaining challenges {.smaller}

::: {.fragment fragment-index=1}
**1. We are generating and storing vast amounts of video data.**

Determine & share best practices for video compression.
:::

::: {.fragment fragment-index=1}
![](img/video_processing.png){height=200}
:::

::: {.fragment fragment-index=2}
**2. Requirements for manual data annotation are honerous.**

- Can we leverage self-supervised pre-training like [beast](https://github.com/paninski-lab/beast)?
- *Sofía* would be interested in making `beast` more plug-and-play for various CV tasks.
:::


## Links {.smaller}

#### {{< fa brands python >}} `movement` 

- {{< fa globe >}} https://movement.neuroinformatics.dev/
- {{< fa brands github >}} https://github.com/neuroinformatics-unit/movement

#### {{< fa brands python >}}  `ethology`

- {{< fa globe >}} https://ethology.neuroinformatics.dev/
- {{< fa brands github >}} https://github.com/neuroinformatics-unit/ethology

#### {{< fa book-open >}} `animals-in-motion`

- {{< fa globe >}} https://animals-in-motion.neuroinformatics.dev/
- {{< fa brands github >}} https://github.com/neuroinformatics-unit/course-animals-in-motion
